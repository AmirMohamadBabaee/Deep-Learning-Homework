{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_zBh5XkFS2x"
      },
      "source": [
        "# In the name of God\n",
        "### HW6\n",
        "### Deep Q-Learning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le8_aVDDFwXN"
      },
      "source": [
        "**Name:** Amir Mohammad Babaei\n",
        "\n",
        "**Std. No.:** 402212399"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43stiMNMF00N"
      },
      "source": [
        "\n",
        "### Deep Q-Learning (DQN)\n",
        "\n",
        "Deep Q-Learning is a popular algorithm in reinforcement learning that combines the ideas of Q-learning, a traditional reinforcement learning method, with deep neural networks. The goal is to train an agent to make decisions by estimating the optimal action-value function Q, which represents the expected cumulative future rewards for taking a particular action in a given state.\n",
        "\n",
        "Key components of DQN:\n",
        "\n",
        "- **Experience Replay:** To break the temporal correlation in sequential data and improve sample efficiency, we use an experience replay buffer to store and sample past experiences.\n",
        "- **Target Networks:** The use of two separate networks, the main network and a target network, helps stabilize training by decoupling the update targets from the online network's constantly changing values.\n",
        "\n",
        "### The Lunar Lander Problem\n",
        "\n",
        "The task is to control a lunar lander and guide it to land safely on the moon's surface. The agent needs to learn a policy that takes into account the lunar lander's state (position, velocity, angle, angular velocity, etc.) and chooses appropriate actions (thrust left, thrust right, thrust up, or do nothing) to achieve a safe landing.\n",
        "\n",
        "### Overview\n",
        "\n",
        "- **Environment:** LunarLander-v2 from OpenAI Gym.\n",
        "- **Objective:** Train an agent to learn a policy for landing the lunar lander safely.\n",
        "- **Techniques:** Deep Q-Learning, Experience Replay, Target Networks.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "1. Follow the instructions and comments in the code cells to implement and understand each component.\n",
        "2. Replace the `#####TO DO#####` placeholders with your code.\n",
        "3. Experiment with hyperparameters and observe how they affect the training process.\n",
        "4. Run the notebook to train the agent and play the game with the trained model.\n",
        "5. Answer any provided questions or tasks to reinforce your understanding.\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "Make sure you have the following libraries installed:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H_SIKDiCCBfC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "3403e62d-bdef-4fab-ce81-6cb8e6f40be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-69.0.3-py3-none-any.whl (819 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.5/819.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-69.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade setuptools wheel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DllO2OwTCjh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7581aa6b-0de9-4c3a-d305-4151d7487180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.1.1.post1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1.post1\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Collecting box2d-py==2.3.5 (from gym[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0 (from gym[box2d])\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (4.1.1.post1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2373080 sha256=e651c7ed2083ca820d2dea570a63f3a0b3040c06926d020e8c6da6d1df248b6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py, pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "Successfully installed box2d-py-2.3.5 pygame-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install swig\n",
        "!pip install gym[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWLFFqKfGcip"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MJG1tV3p-8EM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f7a29c-7bb1-4f5a-9b02-2b95491cecf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import random\n",
        "\n",
        "\n",
        "env = gym.make('LunarLander-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_k--sktuIFlO"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, in_features, n_actions):\n",
        "        \"\"\"\n",
        "        Initialize the Deep Q-Network (DQN).\n",
        "\n",
        "        Parameters:\n",
        "        - in_features (int): Number of input features (dimension of the state).\n",
        "        - n_actions (int): Number of possible actions in the environment.\n",
        "        \"\"\"\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        # TODO: Implement the neural network architecture\n",
        "        # Use Linear layers with ReLU\n",
        "        # Number of hidden units in each layer:\n",
        "        # - Layer 1: 256 units\n",
        "        # - Layer 2: 128 units\n",
        "        # - Layer 3: 64 units\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(in_features, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(64, n_actions)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define the forward pass of the neural network.\n",
        "\n",
        "        Parameters:\n",
        "        - x (torch.Tensor): Input tensor representing the state.\n",
        "\n",
        "        Returns:\n",
        "        - torch.Tensor: Output tensor representing Q-values for each action.\n",
        "        \"\"\"\n",
        "        # TODO: Implement the forward pass\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "B6zGowe__ac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0ed8bf-e346-4cb8-d4b7-6266c508b2a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class ExperienceBuffer():\n",
        "    def __init__(self, capacity):\n",
        "        \"\"\"\n",
        "        Initialize the Experience Replay Buffer.\n",
        "\n",
        "        Parameters:\n",
        "        - capacity (int): Maximum capacity of the buffer.\n",
        "        \"\"\"\n",
        "        self.exp_buffer = collections.deque(maxlen=capacity)\n",
        "\n",
        "    def append(self, exp):\n",
        "        \"\"\"\n",
        "        Append a new experience to the buffer.\n",
        "\n",
        "        Parameters:\n",
        "        - exp (tuple): Tuple representing a single experience (state, action, reward, done, next_state).\n",
        "        \"\"\"\n",
        "        self.exp_buffer.append(exp)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the current size of the buffer.\n",
        "\n",
        "        Returns:\n",
        "        - int: Number of experiences currently stored in the buffer.\n",
        "        \"\"\"\n",
        "        return len(self.exp_buffer)\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"Clear all experiences from the buffer.\"\"\"\n",
        "        self.exp_buffer.clear()\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"\n",
        "        TODO: Sample a batch of experiences from the buffer.\n",
        "\n",
        "        Parameters:\n",
        "        - batch_size (int): Size of the batch to be sampled.\n",
        "\n",
        "        Returns:\n",
        "        - tuple: Batch of experiences (states, actions, rewards, dones, next_states).\n",
        "        \"\"\"\n",
        "        # TODO: Implement the sampling logic\n",
        "\n",
        "\n",
        "        # TODO: Convert to NumPy arrays with appropriate data types\n",
        "        sample_batch = random.sample(self.exp_buffer, batch_size)\n",
        "        states      = np.array([instance[0] for instance in sample_batch])\n",
        "        actions     = np.array([instance[1] for instance in sample_batch])\n",
        "        rewards     = np.array([instance[2] for instance in sample_batch], dtype=np.float32)\n",
        "        dones       = np.array([instance[3] for instance in sample_batch], dtype=np.uint8)\n",
        "        next_states = np.array([instance[4] for instance in sample_batch])\n",
        "        return states, actions, rewards, dones, next_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "id": "G8ZC4Jbc_oo6"
      },
      "outputs": [],
      "source": [
        "class Agent():\n",
        "    def __init__(self, env, buffer):\n",
        "        \"\"\"\n",
        "        Initialize the agent.\n",
        "\n",
        "        Parameters:\n",
        "        - env: The environment the agent interacts with.\n",
        "        - buffer: Experience replay buffer to store agent experiences.\n",
        "        \"\"\"\n",
        "        self.env = env\n",
        "        self.buffer = buffer\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self):\n",
        "        \"\"\"\n",
        "        Reset the agent's state and total rewards to the initial state.\n",
        "        \"\"\"\n",
        "        self.state = env.reset()\n",
        "        self.total_rewards = 0.0\n",
        "\n",
        "    def step(self, net, eps, device=\"cpu\"):\n",
        "        \"\"\"\n",
        "        TODO: Implement the exploration-exploitation strategy (epsilon-greedy) here.\n",
        "\n",
        "        Take a step in the environment using the provided neural network.\n",
        "\n",
        "        Parameters:\n",
        "        - net: The neural network representing the agent's policy.\n",
        "        - eps (float): Epsilon value for epsilon-greedy exploration.\n",
        "        - device (str): Device for neural network computations.\n",
        "\n",
        "        Returns:\n",
        "        - done_reward: Total rewards obtained in the episode if it is finished, otherwise None.\n",
        "        \"\"\"\n",
        "        done_reward = None\n",
        "\n",
        "        # TODO: Implement exploration-exploitation strategy here\n",
        "        if np.random.random() < eps:\n",
        "            # exploration\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            # exploitation\n",
        "            state_prev = torch.tensor(self.state).to(device)\n",
        "            action = int(torch.argmax(net(state_prev).to(device)))\n",
        "\n",
        "        # TODO: Take the selected action for 4 time steps (adjustable)\n",
        "        done = False\n",
        "        state_prev = self.state\n",
        "        for _ in range(4):\n",
        "            self.state, reward, done, info = env.step(action)\n",
        "            self.total_rewards += reward\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # TODO: Append the experience to the buffer\n",
        "        self.buffer.append((state_prev, action, reward, done, self.state))\n",
        "        if done:\n",
        "            done_reward = self.total_rewards\n",
        "            self._reset()\n",
        "\n",
        "        return done_reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "id": "U5sWRHaU_fD7"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "GAMMA = 0.99  # Discount factor for future rewards\n",
        "EPSILON_START = 1.0  # Initial exploration probability (epsilon-greedy)\n",
        "EPSILON_FINAL = 0.01  # Final exploration probability (epsilon-greedy)\n",
        "EPSILON_DECAY_OBS = 10**5  # Number of observations for epsilon decay\n",
        "BATCH_SIZE = 32  # Size of the experience replay batch\n",
        "MEAN_GOAL_REWARD = 250  # Mean reward goal for solving the environment\n",
        "REPLAY_BUFFER_SIZE = 10000  # Maximum capacity of the experience replay buffer\n",
        "REPLAY_MIN_SIZE = 10000  # Minimum size of the experience replay buffer before training begins\n",
        "LEARNING_RATE = 1e-4  # Learning rate for the neural network optimizer\n",
        "SYNC_TARGET_OBS = 1000  # Number of observations before synchronizing target and online networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FItvw2-BD6gm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def cal_loss(batch, net, tgt_net, device='cpu'):\n",
        "    \"\"\"\n",
        "    TODO: Implement the loss calculation for Deep Q-Learning.\n",
        "\n",
        "    Calculate the loss for Deep Q-Learning.\n",
        "\n",
        "    Parameters:\n",
        "    - batch (tuple): Batch of experiences (states, actions, rewards, dones, next_states).\n",
        "    - net: The neural network representing the online Q-network.\n",
        "    - tgt_net: The neural network representing the target Q-network.\n",
        "    - device (str): Device for neural network computations (default is \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: Loss value calculated using Mean Squared Error (MSE) loss.\n",
        "    \"\"\"\n",
        "\n",
        "    states, actions, rewards, dones, next_states = batch\n",
        "    states_v = torch.tensor(states).to(device)\n",
        "    actions_v = torch.tensor(actions).to(device)\n",
        "    rewards_v = torch.tensor(rewards).to(device)\n",
        "    dones_v = torch.BoolTensor(dones).to(device)\n",
        "    next_states_v = torch.tensor(next_states).to(device)\n",
        "\n",
        "    # TODO: Calculate Q-values for the current states and selected actions\n",
        "    Q_val = net(states_v).gather(1, actions_v.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "    # TODO: Calculate the maximum Q-value for the next states using the target network\n",
        "    Q_val_next = tgt_net(next_states_v).max(1)[0]\n",
        "\n",
        "    # TODO: Zero out Q-values for terminal states\n",
        "    Q_val_next[dones_v] = 0.0\n",
        "\n",
        "    # TODO: Detach Q-values for the next states to avoid gradient flow\n",
        "    Q_val_next = Q_val_next.detach()\n",
        "\n",
        "    # TODO: Calculate the expected return for the current states\n",
        "    expected_return = rewards_v + GAMMA * Q_val_next\n",
        "\n",
        "    # TODO: Implement the Mean Squared Error (MSE) loss calculation\n",
        "    loss = nn.MSELoss()(Q_val, expected_return)\n",
        "\n",
        "    return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZadHztDQVs0"
      },
      "source": [
        "# Learning Curves\n",
        " Plot learning curves showing key metrics (e.g., total rewards, loss) over the course of training. Analyze the trends and identify key points in the learning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NdXuc3WBAjbi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "973d1347-9973-4725-eb74-36ba030e6c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAME : 84523, TIME ECLAPSED : 1.3826909065246582, EPSILON : 0.15476999999999996, MEAN_REWARD : -61.191319711232275\n",
            "Reward -63.836169201453096 -> -61.191319711232275 Model Saved\n",
            "GAME : 85276, TIME ECLAPSED : 0.4211914539337158, EPSILON : 0.14724000000000004, MEAN_REWARD : -47.7969179931446\n",
            "Reward -52.08736339851499 -> -47.7969179931446 Model Saved\n",
            "GAME : 85568, TIME ECLAPSED : 0.40212535858154297, EPSILON : 0.14432, MEAN_REWARD : -39.01690578747093\n",
            "Reward -41.79446345669103 -> -39.01690578747093 Model Saved\n",
            "GAME : 86033, TIME ECLAPSED : 0.3099517822265625, EPSILON : 0.13966999999999996, MEAN_REWARD : -29.03843095625437\n",
            "Reward -29.978769678847975 -> -29.03843095625437 Model Saved\n",
            "GAME : 86523, TIME ECLAPSED : 0.26012444496154785, EPSILON : 0.13476999999999995, MEAN_REWARD : -17.624098201069742\n",
            "Reward -19.117072359773978 -> -17.624098201069742 Model Saved\n",
            "GAME : 86902, TIME ECLAPSED : 0.4002063274383545, EPSILON : 0.13097999999999999, MEAN_REWARD : -4.5524386956591885\n",
            "Reward -8.417126534150135 -> -4.5524386956591885 Model Saved\n",
            "GAME : 87200, TIME ECLAPSED : 0.7818830013275146, EPSILON : 0.128, MEAN_REWARD : 6.201632567240615\n",
            "Reward 1.928296318092595 -> 6.201632567240615 Model Saved\n",
            "GAME : 87453, TIME ECLAPSED : 0.47251129150390625, EPSILON : 0.12546999999999997, MEAN_REWARD : 17.39128684926709\n",
            "Reward 14.470499833134822 -> 17.39128684926709 Model Saved\n",
            "GAME : 87694, TIME ECLAPSED : 0.41570091247558594, EPSILON : 0.12305999999999995, MEAN_REWARD : 27.609559349989777\n",
            "Reward 25.338640201151765 -> 27.609559349989777 Model Saved\n",
            "GAME : 88071, TIME ECLAPSED : 0.585120439529419, EPSILON : 0.11929000000000001, MEAN_REWARD : 41.35691708938396\n",
            "Reward 38.69753233583695 -> 41.35691708938396 Model Saved\n",
            "GAME : 88431, TIME ECLAPSED : 0.3153550624847412, EPSILON : 0.11568999999999996, MEAN_REWARD : 56.189374864621115\n",
            "Reward 52.937857010565914 -> 56.189374864621115 Model Saved\n",
            "GAME : 88877, TIME ECLAPSED : 0.6180429458618164, EPSILON : 0.11123000000000005, MEAN_REWARD : 64.81768151787712\n",
            "Reward 64.31716545361873 -> 64.81768151787712 Model Saved\n",
            "GAME : 89543, TIME ECLAPSED : 0.3058779239654541, EPSILON : 0.10457000000000005, MEAN_REWARD : 79.32977994021229\n",
            "Reward 76.03983800703665 -> 79.32977994021229 Model Saved\n",
            "GAME : 89907, TIME ECLAPSED : 0.3399660587310791, EPSILON : 0.10092999999999996, MEAN_REWARD : 89.75505727758984\n",
            "Reward 86.29706762641518 -> 89.75505727758984 Model Saved\n",
            "GAME : 90341, TIME ECLAPSED : 0.6519589424133301, EPSILON : 0.09658999999999995, MEAN_REWARD : 100.96037857270065\n",
            "Reward 98.71184776113965 -> 100.96037857270065 Model Saved\n",
            "GAME : 90742, TIME ECLAPSED : 0.9065375328063965, EPSILON : 0.09258, MEAN_REWARD : 110.98725143677912\n",
            "Reward 109.00014198522891 -> 110.98725143677912 Model Saved\n",
            "GAME : 91194, TIME ECLAPSED : 0.3795652389526367, EPSILON : 0.08806000000000003, MEAN_REWARD : 126.96224175206007\n",
            "Reward 119.87644760591382 -> 126.96224175206007 Model Saved\n",
            "GAME : 91323, TIME ECLAPSED : 0.36811137199401855, EPSILON : 0.08677000000000001, MEAN_REWARD : 132.67391005173369\n",
            "Reward 130.0562926136374 -> 132.67391005173369 Model Saved\n",
            "GAME : 91678, TIME ECLAPSED : 0.875525712966919, EPSILON : 0.08321999999999996, MEAN_REWARD : 142.16891448744983\n",
            "Reward 141.59936521573786 -> 142.16891448744983 Model Saved\n",
            "GAME : 92082, TIME ECLAPSED : 0.3230283260345459, EPSILON : 0.07918000000000003, MEAN_REWARD : 154.65829214030185\n",
            "Reward 151.88467674511259 -> 154.65829214030185 Model Saved\n",
            "GAME : 92599, TIME ECLAPSED : 0.6670777797698975, EPSILON : 0.07401000000000002, MEAN_REWARD : 166.50630374559924\n",
            "Reward 163.90852115652143 -> 166.50630374559924 Model Saved\n",
            "GAME : 93218, TIME ECLAPSED : 0.3708364963531494, EPSILON : 0.06781999999999999, MEAN_REWARD : 175.04198082032806\n",
            "Reward 174.89672430193804 -> 175.04198082032806 Model Saved\n",
            "GAME : 94006, TIME ECLAPSED : 0.3093292713165283, EPSILON : 0.05993999999999999, MEAN_REWARD : 185.60262423606045\n",
            "Reward 185.1359312235592 -> 185.60262423606045 Model Saved\n",
            "GAME : 94683, TIME ECLAPSED : 0.30019283294677734, EPSILON : 0.05317000000000005, MEAN_REWARD : 195.74086030869657\n",
            "Reward 195.4715699823949 -> 195.74086030869657 Model Saved\n",
            "GAME : 97956, TIME ECLAPSED : 0.422360897064209, EPSILON : 0.020440000000000014, MEAN_REWARD : 206.33454232166036\n",
            "Reward 205.80849038684454 -> 206.33454232166036 Model Saved\n",
            "GAME : 99780, TIME ECLAPSED : 0.30505943298339844, EPSILON : 0.01, MEAN_REWARD : 216.27634664759344\n",
            "Reward 215.95331187669487 -> 216.27634664759344 Model Saved\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAME : 100475, TIME ECLAPSED : 0.26540708541870117, EPSILON : 0.01, MEAN_REWARD : 228.1164960996626\n",
            "Reward 227.84158373875664 -> 228.1164960996626 Model Saved\n",
            "GAME : 102640, TIME ECLAPSED : 0.6473569869995117, EPSILON : 0.01, MEAN_REWARD : 241.90195466724978\n",
            "Reward 241.54428420851778 -> 241.90195466724978 Model Saved\n",
            "SOLVED in 103472 obs\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "net = DQN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
        "tgt_net = DQN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
        "\n",
        "buffer = ExperienceBuffer(REPLAY_BUFFER_SIZE)\n",
        "\n",
        "agent = Agent(env, buffer)\n",
        "\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Lists to track total rewards and losses over training\n",
        "total_rewards = []\n",
        "losses = []\n",
        "\n",
        "# Initialize time variables for tracking training time\n",
        "ts = time.time()\n",
        "best_mean_reward = None\n",
        "obs_id = 0\n",
        "\n",
        "while True:\n",
        "    obs_id += 1\n",
        "\n",
        "    # Update exploration rate based on epsilon decay schedule\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - obs_id/EPSILON_DECAY_OBS)\n",
        "\n",
        "    # Agent takes a step in the environment, receives a reward\n",
        "    reward = agent.step(net, epsilon, device=device)\n",
        "\n",
        "    if reward is not None:\n",
        "        # Store total rewards and update game time\n",
        "        total_rewards.append(reward)\n",
        "        game_time = time.time() - ts\n",
        "        ts = time.time()\n",
        "        mean_reward = np.mean(total_rewards[-100:])\n",
        "\n",
        "        if best_mean_reward is None or best_mean_reward < mean_reward:\n",
        "            torch.save(net.state_dict(), './lunar_lander-best.dat')\n",
        "\n",
        "            if best_mean_reward is None:\n",
        "                last = mean_reward\n",
        "                best_mean_reward = mean_reward\n",
        "\n",
        "            if best_mean_reward is not None and best_mean_reward - last > 10:\n",
        "                last = best_mean_reward\n",
        "                print(\"GAME : {}, TIME ECLAPSED : {}, EPSILON : {}, MEAN_REWARD : {}\"\n",
        "                      .format(obs_id, game_time, epsilon, mean_reward))\n",
        "                print(\"Reward {} -> {} Model Saved\".format(best_mean_reward, mean_reward))\n",
        "\n",
        "            best_mean_reward = mean_reward\n",
        "\n",
        "        if mean_reward > MEAN_GOAL_REWARD:\n",
        "            print(\"SOLVED in {} obs\".format(obs_id))\n",
        "            break\n",
        "\n",
        "    # Continue training if the replay buffer size is below the minimum required\n",
        "    if len(buffer) < REPLAY_MIN_SIZE:\n",
        "        continue\n",
        "\n",
        "    # Synchronize target network with the Q-network at regular intervals\n",
        "    if obs_id % SYNC_TARGET_OBS == 0:\n",
        "        tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    # TODO: Implement the training process (calculating loss, backpropagation, and optimizer step)\n",
        "    optimizer.zero_grad()\n",
        "    batch = buffer.sample(BATCH_SIZE)\n",
        "    loss_t = cal_loss(batch, net, tgt_net, device=device)\n",
        "    losses.append(loss_t.item())\n",
        "    loss_t.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # TODO: Plot learning curves every few episodes or steps\n",
        "    if obs_id % 100000 == 0 and obs_id != 0:\n",
        "        plt.plot(losses, label='Loss')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss Over Episodes')\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwZygyvBOzLe"
      },
      "source": [
        "# Visual Comparison:\n",
        "\n",
        "write a function to render and display the environment before and after training. What visual differences do you observe in the agent's behavior? Discuss it. Also, Upload the Videos with your notebook. You can use the following library for rendering and saving videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9_ClI7VqMHgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d259dbea-e51e-40d3-e7bc-b70c9b4b7077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### BEFORE TRAINING ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### AFTER TRAINING ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        }
      ],
      "source": [
        "import imageio\n",
        "\n",
        "# Helper function for rendering and saving a video\n",
        "def render_and_save_video(env, net, episodes=10, save_path=\"./render_video.mp4\", device=\"cpu\"):\n",
        "    # TODO: Render and display the environment\n",
        "    images = []  # List to store frames\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            # Render the current state\n",
        "            frame = env.render(mode='rgb_array')\n",
        "            images.append(frame)\n",
        "\n",
        "            # Convert observation to tensor and move to the specified device\n",
        "            obs = torch.FloatTensor(np.array([obs], dtype=np.float32)).to(device)\n",
        "\n",
        "            # Choose the action using the trained network\n",
        "            with torch.no_grad():\n",
        "                action = net(obs).argmax(dim=1).item()\n",
        "\n",
        "            # Take a step in the environment\n",
        "            obs, _, done, _ = env.step(action)\n",
        "\n",
        "    # Save the frames as a video\n",
        "    imageio.mimsave(save_path, images)\n",
        "\n",
        "\n",
        "# Render and save a video before training\n",
        "print(\"### BEFORE TRAINING ###\")\n",
        "render_and_save_video(env, net, device=device,save_path = './before.mp4')\n",
        "\n",
        "# Render and save a video after training\n",
        "print(\"### AFTER TRAINING ###\")\n",
        "render_and_save_video(env, net, device=device,save_path = './after.mp4')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsGQY4DQ9Z_"
      },
      "source": [
        "# Question:\n",
        "\n",
        "Exploration (Epsilon-Greedy):\n",
        "\n",
        "Discuss the significance of the exploration strategy, specifically the Epsilon-Greedy approach, in balancing exploration and exploitation during training."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "The Epsilon-Greedy approach is a strategy used in reinforcement learning to balance exploration and exploitation during training. This method helps the agent learn what to do by mapping situations to actions, maximizing rewards while also exploring new possibilities[1]. The key aspects of the Epsilon-Greedy approach include:\n",
        "\n",
        "- **Exploration**: This involves trying new actions and learning about the environment to improve the agent's understanding of the best actions to take[1].\n",
        "\n",
        "- **Exploitation**: This involves choosing the action with the highest estimated reward based on the agent's current knowledge[1].\n",
        "\n",
        "- **Epsilon-Greedy Action Selection**: This method selects the action with the highest estimated reward most of the time, but with a small probability (epsilon), it chooses a random action independent of the action-value estimates[2]. The value of epsilon can be adjusted during the training process to fine-tune the exploration-exploitation tradeoff[5].\n",
        "\n",
        "The Epsilon-Greedy approach helps the agent strike a balance between exploration and exploitation, allowing it to take advantage of prior knowledge while also exploring new possibilities[2]. This strategy enables the agent to learn more about the environment and improve its action-value estimates, leading to more informed decisions in the future[1]. By using the Epsilon-Greedy approach, the agent can avoid getting stuck in suboptimal states or missing out on better options due to a lack of exploration[2].\n",
        "\n",
        "```\n",
        "Citations:\n",
        "[1] https://www.geeksforgeeks.org/epsilon-greedy-algorithm-in-reinforcement-learning/\n",
        "[2] https://www.baeldung.com/cs/epsilon-greedy-q-learning\n",
        "[3] https://deeplizard.com/learn/video/mo96Nqlo1L8\n",
        "[4] https://towardsdatascience.com/striking-a-balance-between-exploring-and-exploiting-5475d9c1e66e\n",
        "[5] https://serp.ai/epsilon-greedy-exploration/\n",
        "```"
      ],
      "metadata": {
        "id": "SiwMtkMPh8mO"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}